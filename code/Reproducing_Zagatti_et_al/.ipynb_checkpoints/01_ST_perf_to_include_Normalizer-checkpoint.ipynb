{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b05cb3-6262-4785-9439-a0543ced1883",
   "metadata": {},
   "source": [
    "In this notebook we will load the CSV datasets that we previously preprocessed and split, apply the scaling techniques and then measure the performance of several classifiers on these datasets when scaled with the distinc scaling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dcaa1-ce7a-4041-b45f-6abc45b8ed1b",
   "metadata": {},
   "source": [
    "# Importing required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950349b-4698-4b77-be34-ee2d461b5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Started loading libs')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fb5bb-86e9-47d6-8886-7e526ec9e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# #from sklearn.preprocessing import PowerTransformer\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#!pip install sklearn_lvq\n",
    "from sklearn_lvq import GlvqModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from deslib.dcs import OLA\n",
    "from deslib.dcs import MCB\n",
    "from deslib.dcs import LCA\n",
    "from deslib.des import KNORAU\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des import METADES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69238727-4587-4ec8-b583-6481e3485df5",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "Here we are going to load the data that we previously preprocessed, split into 5-folds and saved in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7ab58-6575-49bf-b89e-15b06eafe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a dict structure such that I can access train fold 1 from \n",
    "# dataset D1 as datasets[1]['train'][0]\n",
    "print('Loading data ', end='')\n",
    "data_dir = '../../data/5-fold'\n",
    "datasets = {}\n",
    "for i in range(1,301):\n",
    "    datasets[i] = {}\n",
    "    datasets[i]['train'] = []\n",
    "    datasets[i]['test'] = []\n",
    "    for f in range(1,6): #for each fold\n",
    "        csv_filename = f'{data_dir}/D{i}-fold{f}-train.csv'\n",
    "        df_train = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, on_bad_lines='skip')\n",
    "        csv_filename = f'{data_dir}/D{i}-fold{f}-test.csv'\n",
    "        df_test = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, on_bad_lines='skip')\n",
    "        datasets[i]['train'].append(df_train)\n",
    "        datasets[i]['test'].append(df_test)\n",
    "    print('.', end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c53005-b436-4c2c-966d-5a82c6b00116",
   "metadata": {},
   "source": [
    "# Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf34617-d118-4e3b-989c-a1c463ae8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaling ', end='')\n",
    "# Creating copies of the datasets:\n",
    "datasets_nor = copy.deepcopy(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f4857-fc79-4c4b-94bd-7a1d802301fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor = Normalizer()\n",
    "\n",
    "for i in range(1,301):\n",
    "    for fold in range(5):\n",
    "        #print(f'Dataset: {name}, fold {fold}.', end = '')\n",
    "        datasets_nor[i]['train'][fold].iloc[:,:-1] = nor.fit_transform(datasets_nor[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_nor[i]['test'][fold].iloc[:,:-1] = nor.transform(datasets_nor[i]['test'][fold].iloc[:,:-1])\n",
    "    print('.', end='') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45977d2a-a61d-404a-a9f8-5ff7006af5a6",
   "metadata": {},
   "source": [
    "# Training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ce99a-410d-458a-91c9-6b4985bdfc9c",
   "metadata": {},
   "source": [
    "### Creating functions to cross-validate models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531c064-d4cc-464f-822a-3c59f90f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, model_name, results_df):\n",
    "    # superset = {'NS': datasets, 'SS': datasets_ss,\n",
    "    #         'MMS': datasets_mms,'MAS':datasets_mas,\n",
    "    #         'RS':datasets_rs, #'PT': datasets_pt, \n",
    "    #         'QT': datasets_qt}\n",
    "    superset = {'NOR': datasets_nor}\n",
    "    \n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in range(1,301): #name is actually a number\n",
    "    #for name in [1]: #testing \n",
    "        print(f'\\rCurrent dataset: {name}', end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                #print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                # Train model with the training data, \n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Test model:\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "                precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label=1)\n",
    "                #roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                recall_folds.append(recall)\n",
    "                precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                #roc_auc_folds.append(roc_auc)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "#                        'roc_auc_fold1' : roc_auc_folds[0], 'roc_auc_fold2' : roc_auc_folds[1], 'roc_auc_fold3' : roc_auc_folds[2], \n",
    "#                        'roc_auc_fold4' : roc_auc_folds[3], 'roc_auc_fold5' : roc_auc_folds[4], \n",
    "#                        'roc_auc_mean': np.mean(f1_folds), 'roc_auc_stddev': np.std(roc_auc_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds),\n",
    "                      }\n",
    "\n",
    "            #results_df = results_df.append(new_row, ignore_index=True) #Deprecated\n",
    "            results_df = pd.concat([results_df, pd.DataFrame.from_records([new_row])],ignore_index=True)\n",
    "            results_df.to_csv(f'results_mono_NOR_perfs_PARTIAL.csv')\n",
    "    print('Finishing '+ model_name +', time: ', datetime.now())   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799c311-b53a-42e8-b482-84f61b7a4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is for ensemble models that need a prefit pool of base classifiers:\n",
    "def run_model2(model, model_name, pool, results_df):\n",
    "    # superset = {'NS': datasets, 'SS': datasets_ss,\n",
    "    #         'MMS': datasets_mms,'MAS':datasets_mas,\n",
    "    #         'RS':datasets_rs, #'PT': datasets_pt, \n",
    "    #         'QT': datasets_qt}\n",
    "    superset = {'NOR': datasets_nor}\n",
    "\n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in range(1,301): #name is actually a number\n",
    "    #for name in [1]: #testing with just one dataset\n",
    "        print(f'\\rCurrent dataset: {name}', end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                #print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                # Train model with the training data, \n",
    "                pool.fit(X_train, y_train)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Test model:\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "                precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                recall_folds.append(recall)\n",
    "                precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds),\n",
    "                      }\n",
    "\n",
    "            #results_df = results_df.append(new_row, ignore_index=True) #Deprecated\n",
    "            results_df = pd.concat([results_df, pd.DataFrame.from_records([new_row])],ignore_index=True)\n",
    "            results_df.to_csv(f'results_ensemble_NOR_perfs_PARTIAL.csv')\n",
    "    print('Finishing '+ model_name +', time: ', datetime.now())   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594cc32-4176-41fc-afa0-ae5615a172ac",
   "metadata": {},
   "source": [
    "### Running monolithic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c01c5c-1858-443b-8276-540a4aee22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df_mono = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           'recall_mean':[], 'recall_stddev':[],\n",
    "                           'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })\n",
    "\n",
    "## Instantiating models:\n",
    "# Monolithic models\n",
    "monolithic_models = {'SVM_lin': SVC(kernel='linear', probability=True),\n",
    "                     'SVM_RBF': SVC(kernel='rbf', probability=True),\n",
    "                     #'KNN': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "                     #'GNB': GaussianNB(),\n",
    "                     'GLVQ': GlvqModel(random_state=0), #Generalized Learning Vector Quantization\n",
    "                     #'LDA': LinearDiscriminantAnalysis(),\n",
    "                     #'QDA': QuadraticDiscriminantAnalysis(),\n",
    "                     'GP': GaussianProcessClassifier(1.0 * RBF(1.0), random_state=0, n_jobs=-1),\n",
    "                     #'DT': DecisionTreeClassifier(random_state=0),\n",
    "                     'Percep': Perceptron(random_state=0, n_jobs=-1),\n",
    "                     'MLP': MLPClassifier(activation='relu', solver='adam', alpha=1e-5, max_iter=10000, hidden_layer_sizes=(5, 2), random_state=0)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378cb19-f043-471f-ac97-c43e0ff368b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\", category=UserWarning) # Just to avoid convergence warnings from GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795a64d-c5b8-43cb-90b7-b984cfc0e8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running models:\n",
    "for name,model in monolithic_models.items():\n",
    "        results_df_mono = run_model(model, name, results_df_mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca7df4-bde6-4878-ba4e-7b8ae11bc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mono.to_csv('results_mono_NOR_perfs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f06832-5c0e-42e3-8bc9-4c7ec1e14585",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6c78e-7b4f-4671-8b01-4934a56a9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df_ensemble = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           'recall_mean':[], 'recall_stddev':[],\n",
    "                           'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })\n",
    "\n",
    "\n",
    "#  Ensemble models\n",
    "\n",
    "base_model = Perceptron(random_state=0)\n",
    "pool_classifiers = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1)\n",
    "\n",
    "base_model_calib = CalibratedClassifierCV(base_estimator = Perceptron(random_state=0), cv=5) \n",
    "pool_classifiers_calib = BaggingClassifier(base_estimator=base_model_calib, n_estimators=100, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1) \n",
    "\n",
    "ensemble_models = {#'RF': RandomForestClassifier(random_state = 0, n_jobs=-1),\n",
    "                   #'XGBoost': XGBClassifier(n_jobs=-1, random_state=0),\n",
    "                   #'AdaBoost': AdaBoostClassifier(n_estimators=100),\n",
    "                   'Bagging': pool_classifiers,\n",
    "                   'OLA': OLA(pool_classifiers, random_state=0),\n",
    "                   'LCA': LCA(pool_classifiers, random_state=0),\n",
    "                   'MCB': MCB(pool_classifiers, random_state=0),\n",
    "                   'KNORAE': KNORAE(pool_classifiers, random_state=0),\n",
    "                   'KNORAU': KNORAU(pool_classifiers, random_state=0),\n",
    "                   #'METADES': METADES(pool_classifiers_calib, random_state=0)\n",
    "                  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6195878-2fee-4e67-aa00-6c659c827983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running models:\n",
    "for name,model in ensemble_models.items():\n",
    "    if name in ['OLA','LCA','MCB', 'KNORAE', 'KNORAU']: # these metamodels need pool_classifiers to be fit before applying fit to the metamodel.\n",
    "        results_df_ensemble = run_model2(model, name, pool_classifiers, results_df_ensemble)\n",
    "    elif name in ['METADES']: #This also needs a prefit pool_classifiers but needs base_estimators to return probabilities too.\n",
    "        results_df_ensemble = run_model2(model, name, pool_classifiers_calib, results_df_ensemble)\n",
    "    else: \n",
    "        results_df_ensemble = run_model(model, name, results_df_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c96121-45bf-4f77-be84-7aa9f5c335c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_ensemble.to_csv('results_ensemble_NOR_perfs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87030f3a-fdee-41d8-a52a-5d0067eb8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mono = pd.read_csv('results_mono_NOR_perfs.csv')\n",
    "results_df = pd.concat([results_df_mono, results_df_ensemble], axis=0)\n",
    "results_df.sort_values(by = ['Model', 'Dataset']).to_csv('results_NOR_perfs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44288de4-8643-4da5-9de1-fd1f33bf687e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
