{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b05cb3-6262-4785-9439-a0543ced1883",
   "metadata": {},
   "source": [
    "In this notebook we will load the CSV datasets that we previously preprocessed and split, apply the scaling techniques and then measure the performance of several classifiers on these datasets when scaled with the distinc scaling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dcaa1-ce7a-4041-b45f-6abc45b8ed1b",
   "metadata": {},
   "source": [
    "# Importing required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950349b-4698-4b77-be34-ee2d461b5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Started loading libs')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fb5bb-86e9-47d6-8886-7e526ec9e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#!pip install sklearn_lvq\n",
    "from sklearn_lvq import GlvqModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from deslib.dcs import OLA\n",
    "from deslib.dcs import MCB\n",
    "from deslib.dcs import LCA\n",
    "from deslib.des import KNORAU\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des import METADES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1af7f9-9637-41c2-8d81-8458e7927fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Finished Loading libs')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69238727-4587-4ec8-b583-6481e3485df5",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "Here we are going to load the data that we previously preprocessed, split into 5-folds and saved in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c24316-7438-4f8b-b901-a3552fe1a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ', cwd)\n",
    "if 'ST_performances'not in cwd:\n",
    "    os.chdir(cwd+'/ST_performances')\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ', cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea9543-ff18-46b5-82f2-3e92ea05e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Started loading data')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7ab58-6575-49bf-b89e-15b06eafe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a dict structure such that I can access train fold 1 from \n",
    "# dataset D1 as datasets[1]['train'][0]\n",
    "print('Loading data ', end='')\n",
    "data_dir = '../../data/5-fold'\n",
    "datasets = {}\n",
    "for i in range(1,301):\n",
    "    datasets[i] = {}\n",
    "    datasets[i]['train'] = []\n",
    "    datasets[i]['test'] = []\n",
    "    for f in range(1,6): #for each fold\n",
    "        csv_filename = f'{data_dir}/D{i}-fold{f}-train.csv'\n",
    "        df_train = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, on_bad_lines='skip')\n",
    "        csv_filename = f'{data_dir}/D{i}-fold{f}-test.csv'\n",
    "        df_test = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, on_bad_lines='skip')\n",
    "        datasets[i]['train'].append(df_train)\n",
    "        datasets[i]['test'].append(df_test)\n",
    "    print('.', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51578a-75a8-4e1d-a6a2-caacaccd9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Finished loading data')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f797048-f1d8-4cc2-ba7f-cd96af9999d8",
   "metadata": {},
   "source": [
    "# Checking Imbalance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1a2b6-7c0c-4598-8dcd-440f987feb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's count how many instances we have per class and calculate the imbalance ratios:\n",
    "# cnts = {}\n",
    "# imb_ratios = {}\n",
    "# for key in datasets:\n",
    "#     #First let's create a dataframe containing all data (appending train and test):\n",
    "#     ds = datasets[key]['train'][0].append(datasets[key]['test'][0], ignore_index=True)\n",
    "#     class_att = ds.columns[-1]\n",
    "#     cnt = Counter(ds[class_att])\n",
    "#     cnts[key] = (cnt[list(cnt)[0]], cnt[list(cnt)[1]])\n",
    "#     imb_ratios[key] = max(cnts[key])/min(cnts[key])\n",
    "# #for i in imb_ratios.values(): print('%.2f'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49c835-bb01-4427-8038-346bc2cffbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRs = pd.Series(imb_ratios)\n",
    "# IRs.plot.hist(grid=True, bins=25, rwidth=0.9)\n",
    "# plt.xlabel('Imbalance Ratio')\n",
    "# plt.grid(axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45d51e-ea56-42be-8499-07ed17a7adf8",
   "metadata": {},
   "source": [
    "Most of the datasets are in the \"low imbalance\" range (IR<3), but some are highly imbalanced. Some treatment will have to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb7d49-05df-43d9-8f0b-119f85799bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp = list(Counter(datasets[300]['train'][0]['class']).values())\n",
    "# IR = max(cp)/min(cp)\n",
    "# IR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c53005-b436-4c2c-966d-5a82c6b00116",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "Here, the idea is to create 5 copies of each dataset, for each copy we are going to apply one of the following scaling techniques to the attributes: Standard Scaler, Min-max Scaler, Maximum Absolute Scaler, Robust Scaler and Quantile Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789484c-f589-460d-ae9a-d9c3cc850bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Started Scaling')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf34617-d118-4e3b-989c-a1c463ae8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaling ', end='')\n",
    "# Creating copies of the datasets:\n",
    "datasets_ss = copy.deepcopy(datasets)\n",
    "datasets_mms = copy.deepcopy(datasets)\n",
    "datasets_mas = copy.deepcopy(datasets)\n",
    "datasets_rs = copy.deepcopy(datasets)\n",
    "datasets_qt = copy.deepcopy(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f4857-fc79-4c4b-94bd-7a1d802301fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "mms = MinMaxScaler() \n",
    "mas = MaxAbsScaler() \n",
    "rs = RobustScaler()\n",
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "import warnings\n",
    "# Ignoring warnings from QuantileTransformer when number of samples is lower then 1000:\n",
    "warnings.filterwarnings(action = \"ignore\", category=UserWarning) \n",
    "\n",
    "for i in range(1,301):\n",
    "    for fold in range(5):\n",
    "        #print(f'Dataset: {name}, fold {fold}.', end = '')\n",
    "        datasets_ss[i]['train'][fold].iloc[:,:-1] = ss.fit_transform(datasets_ss[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_ss[i]['test'][fold].iloc[:,:-1] = ss.transform(datasets_ss[i]['test'][fold].iloc[:,:-1])\n",
    "        datasets_mms[i]['train'][fold].iloc[:,:-1] = mms.fit_transform(datasets_mms[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_mms[i]['test'][fold].iloc[:,:-1] = mms.transform(datasets_mms[i]['test'][fold].iloc[:,:-1])\n",
    "        datasets_mas[i]['train'][fold].iloc[:,:-1] = mas.fit_transform(datasets_mas[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_mas[i]['test'][fold].iloc[:,:-1] = mas.transform(datasets_mas[i]['test'][fold].iloc[:,:-1])\n",
    "        datasets_rs[i]['train'][fold].iloc[:,:-1] = rs.fit_transform(datasets_rs[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_rs[i]['test'][fold].iloc[:,:-1] = rs.transform(datasets_rs[i]['test'][fold].iloc[:,:-1])\n",
    "        datasets_qt[i]['train'][fold].iloc[:,:-1] = qt.fit_transform(datasets_qt[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_qt[i]['test'][fold].iloc[:,:-1] = qt.transform(datasets_qt[i]['test'][fold].iloc[:,:-1])\n",
    "    print('.', end='') \n",
    "# Restablishing warnings:\n",
    "warnings.filterwarnings(action = \"default\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf49eaf-ea5e-4d58-baa1-1f0401874006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets[1]['train'][0]['att1'].plot.hist(grid=True, bins=25, rwidth=0.9)\n",
    "# datasets_ss[1]['train'][0]['att1'].plot.hist(grid=True, bins=25, rwidth=0.9)\n",
    "# datasets_qt[1]['train'][0]['att1'].plot.hist(grid=True, bins=25, rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97f844-1be3-415c-b85a-ee95216dbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Finished Scaling')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45977d2a-a61d-404a-a9f8-5ff7006af5a6",
   "metadata": {},
   "source": [
    "# Training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ce99a-410d-458a-91c9-6b4985bdfc9c",
   "metadata": {},
   "source": [
    "### Creating functions to cross-validate models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531c064-d4cc-464f-822a-3c59f90f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, model_name, results_df):\n",
    "    superset = {'NS': datasets, 'SS': datasets_ss,\n",
    "            'MMS': datasets_mms,'MAS':datasets_mas,\n",
    "            'RS':datasets_rs, #'PT': datasets_pt, \n",
    "            'QT': datasets_qt}\n",
    "    \n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in range(1,301): #name is actually a number\n",
    "    #for name in [1]: #testing \n",
    "        print(f'\\nCurrent dataset: {name}', end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                \n",
    "                # @TODO Class balancing with SMOTE?\n",
    "                \n",
    "                # Train model with the training data, \n",
    "                # If we need y_score for calculating ROC-AUC we do:\n",
    "                #y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "                \n",
    "                # If we won't calculate ROC-AUC, we can just fit the model.\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Test model:\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "                precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label=1)\n",
    "                #roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                recall_folds.append(recall)\n",
    "                precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                #roc_auc_folds.append(roc_auc)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "#                        'roc_auc_fold1' : roc_auc_folds[0], 'roc_auc_fold2' : roc_auc_folds[1], 'roc_auc_fold3' : roc_auc_folds[2], \n",
    "#                        'roc_auc_fold4' : roc_auc_folds[3], 'roc_auc_fold5' : roc_auc_folds[4], \n",
    "#                        'roc_auc_mean': np.mean(f1_folds), 'roc_auc_stddev': np.std(roc_auc_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds),\n",
    "                      }\n",
    "\n",
    "            #results_df = results_df.append(new_row, ignore_index=True) #Deprecated\n",
    "            results_df = pd.concat([results_df, pd.DataFrame.from_records([new_row])],ignore_index=True)\n",
    "\n",
    "    print('Finishing '+ model_name +', time: ', datetime.now())   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799c311-b53a-42e8-b482-84f61b7a4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is for ensemble models that need a prefit pool of base classifiers:\n",
    "def run_model2(model, model_name, pool, results_df):\n",
    "    superset = {'NS': datasets, 'SS': datasets_ss,\n",
    "            'MMS': datasets_mms,'MAS':datasets_mas,\n",
    "            'RS':datasets_rs, #'PT': datasets_pt, \n",
    "            'QT': datasets_qt}\n",
    "\n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in range(1,301): #name is actually a number\n",
    "    #for name in [1]: #testing with just one dataset\n",
    "        print(f'\\nCurrent dataset: {name}', end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                # Train model with the training data, \n",
    "                # If we need y_score for calculating ROC-AUC we do:\n",
    "                #y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "                \n",
    "                # If we won't calculate ROC-AUC, we can just fit the model.\n",
    "                # If it is an ensemble model that needs prefit base models, we fit them first:\n",
    "                pool.fit(X_train, y_train)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Test model:\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "                precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label=1)\n",
    "                #roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                recall_folds.append(recall)\n",
    "                precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                #roc_auc_folds.append(roc_auc)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "#                        'roc_auc_fold1' : roc_auc_folds[0], 'roc_auc_fold2' : roc_auc_folds[1], 'roc_auc_fold3' : roc_auc_folds[2], \n",
    "#                        'roc_auc_fold4' : roc_auc_folds[3], 'roc_auc_fold5' : roc_auc_folds[4], \n",
    "#                        'roc_auc_mean': np.mean(f1_folds), 'roc_auc_stddev': np.std(roc_auc_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds),\n",
    "                      }\n",
    "\n",
    "            #results_df = results_df.append(new_row, ignore_index=True) #Deprecated\n",
    "            results_df = pd.concat([results_df, pd.DataFrame.from_records([new_row])],ignore_index=True)\n",
    "\n",
    "    print('Finishing '+ model_name +', time: ', datetime.now())   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72344037-8ee7-4a0d-ab85-c7055ebd7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594cc32-4176-41fc-afa0-ae5615a172ac",
   "metadata": {},
   "source": [
    "### Running monolithic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c01c5c-1858-443b-8276-540a4aee22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df_mono = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           'recall_mean':[], 'recall_stddev':[],\n",
    "                           'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })\n",
    "\n",
    "## Instantiating models:\n",
    "# Monolithic models\n",
    "monolithic_models = {'SVM_lin': SVC(kernel='linear', probability=True),\n",
    "                     'SVM_RBF': SVC(kernel='rbf', probability=True),\n",
    "                     #'KNN': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "                     #'GNB': GaussianNB(),\n",
    "                     'GLVQ': GlvqModel(random_state=0), #Generalized Learning Vector Quantization\n",
    "                     #'LDA': LinearDiscriminantAnalysis(),\n",
    "                     #'QDA': QuadraticDiscriminantAnalysis(),\n",
    "                     'GP': GaussianProcessClassifier(1.0 * RBF(1.0), random_state=0, n_jobs=-1),\n",
    "                     #'DT': DecisionTreeClassifier(random_state=0),\n",
    "                     'Percep': Perceptron(random_state=0, n_jobs=-1),\n",
    "                     'MLP': MLPClassifier(activation='relu', solver='adam', alpha=1e-5, max_iter=10000, hidden_layer_sizes=(5, 2), random_state=0)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d94d9-27b3-4cdf-8d0e-73b1df788177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"monitor.txt\",\"w+\")\n",
    "# f.write('Started running models')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795a64d-c5b8-43cb-90b7-b984cfc0e8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running models:\n",
    "\n",
    "for name,model in monolithic_models.items():\n",
    "        results_df_mono = run_model(model, name, results_df_mono)\n",
    "#results_df_mono.to_csv('../../results/csv_tabs/results_ST_perfs_monolithic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f06832-5c0e-42e3-8bc9-4c7ec1e14585",
   "metadata": {},
   "source": [
    "### Running Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6c78e-7b4f-4671-8b01-4934a56a9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df_ensemble = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           'recall_mean':[], 'recall_stddev':[],\n",
    "                           'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })\n",
    "\n",
    "\n",
    "#  Ensemble models\n",
    "\n",
    "base_model = Perceptron(random_state=0)\n",
    "pool_classifiers = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1)\n",
    "\n",
    "base_model_calib = CalibratedClassifierCV(base_estimator = Perceptron(random_state=0), cv=5) \n",
    "pool_classifiers_calib = BaggingClassifier(base_estimator=base_model_calib, n_estimators=100, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1) \n",
    "\n",
    "ensemble_models = {#'RF': RandomForestClassifier(random_state = 0, n_jobs=-1),\n",
    "                   #'XGBoost': XGBClassifier(n_jobs=-1, random_state=0),\n",
    "                   #'AdaBoost': AdaBoostClassifier(n_estimators=100),\n",
    "                   'Bagging': pool_classifiers,\n",
    "                   'OLA': OLA(pool_classifiers, random_state=0),\n",
    "                   'LCA': LCA(pool_classifiers, random_state=0),\n",
    "                   'MCB': MCB(pool_classifiers, random_state=0),\n",
    "                   'KNORAE': KNORAE(pool_classifiers, random_state=0),\n",
    "                   'KNORAU': KNORAU(pool_classifiers, random_state=0),\n",
    "                   #'METADES': METADES(pool_classifiers_calib, random_state=0)\n",
    "                  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6195878-2fee-4e67-aa00-6c659c827983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running models:\n",
    "for name,model in ensemble_models.items():\n",
    "    if name in ['OLA','LCA','MCB', 'KNORAE', 'KNORAU']: # these metamodels need pool_classifiers to be fit before applying fit to the metamodel.\n",
    "        results_df_ensemble = run_model2(model, name, pool_classifiers, results_df_ensemble)\n",
    "    elif name in ['METADES']: #This also needs a prefit pool_classifiers but needs base_estimators to return probabilities too.\n",
    "        results_df_ensemble = run_model2(model, name, pool_classifiers_calib, results_df_ensemble)\n",
    "    else: \n",
    "        results_df_ensemble = run_model(model, name, results_df_ensemble)\n",
    "#results_df_ensemble.to_csv('../../results/csv_tabs/results_ST_perfs_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87030f3a-fdee-41d8-a52a-5d0067eb8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_df_mono, results_df_ensemble], axis=0)\n",
    "results_df.sort_values(by = ['Model', 'Dataset']).to_csv('../../results/csv_tabs/results_ST_perfs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cda7ba-774b-45d0-8f37-b43fad15e1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python 3.8.10 kernel (jupyter1)",
   "language": "python",
   "name": "jupyter1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
