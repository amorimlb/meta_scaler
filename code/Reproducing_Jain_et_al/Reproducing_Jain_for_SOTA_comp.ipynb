{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637921bf-8d30-42e9-b81a-cabb9bcc4ebf",
   "metadata": {},
   "source": [
    "We need to reproduce, in part, the study by Jain et al. \"Dynamic selection of normalization techniques using data complexity measures\" in order to compare its performance with the Meta-scaler. Their code is not publicly available and the authors did not respond to our requests via e-mail. Our only guide will be the information in the paper.\n",
    "\n",
    "What we know:\n",
    "- Their set of meta-features:\n",
    "F1, F2, F3, N2, N3, T1, T2, D1 (density), N4, L1, L2, L3.\n",
    "\n",
    "These are all available in the PyMFE library.\n",
    "\n",
    "- Their ST selection:\n",
    "MinMaxScaler and StandardScaler\n",
    "\n",
    "- Their method for constructing the meta-dataset:\n",
    "1. Scale all datasets with both STs (resulting in two versions of each DS).\n",
    "2. Evaluate the performance of a Gaussian Kernel ELM on both versions of the DS (with 5-fold CV) and define the label of each instance (dataset) as the name of the ST with maximum performance.\n",
    "Notice that there is no 'NS' (nonscaled) label, hence the trained system will always recommend to scale the data.\n",
    "3. Merge the label for each DS with the 12 extracted meta-features for the same DS.\n",
    "\n",
    "- The classification algorithms they use to train their meta-models:\n",
    "ELM, SVM, MLP, Complement Naive Bayes, Naive Bayes Mutinomial, Naive Bayes Mutinomial Updateable, FT, OneR, Bayesian Logistic regression, Random Forest, RIDOR, J48, RBF Network, lbk.\n",
    "Since their best result was obtained with the ELM, we are going to use this algorithm only and create only one meta-model to compare with our approach. Note: in the paper they detail that they used the GKELM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1c7d6bd9-7a91-4119-8908-fcb6ab14c88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy.io.arff import loadarff\n",
    "from datetime import datetime\n",
    "import missingno as msno\n",
    "from sklearn import preprocessing\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.impute import KNNImputer\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Let's import our slightly modified version of the elm package available at https://github.com/acba/elm\n",
    "# We commented out unused parts to reduce dependencies. \n",
    "from elm import elmk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2964f82-65b6-4006-9c40-cd6cd045a74f",
   "metadata": {},
   "source": [
    "# Reading meta-features for the 300 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dba739b-c89f-42e2-b43d-b997ab0263bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, we could extract here the 12 meta-features that they used for our 300 datasets, but we already did \n",
    "# this for our paper. We just have to select only the 12 mfs they used.\n",
    "\n",
    "all_mfs = pd.read_csv('../Meta_features_extraction/pymfe_meta_features.csv')\n",
    "mfs = all_mfs[['f1.mean', 'f2.mean', 'f3.mean', 'n2.mean', 'n3.mean', 't1.mean',\n",
    "               't2',  'density', 'n4.mean', 'l1.mean', 'l2.mean', 'l3.mean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf96c1-8611-4464-9ba5-57064ccb2f6c",
   "metadata": {},
   "source": [
    "# Measuring classification performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b524d1b-8c15-4a63-b698-a25e5ed7630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ............................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "# I will create a dict structure such that I can access train fold 1 from \n",
    "# dataset D1 as datasets[1]['train'][0]\n",
    "print('Loading data ', end='')\n",
    "data_dir = '../../data/5-fold'\n",
    "datasets = {}\n",
    "for i in range(1,301):\n",
    "    datasets[i] = {}\n",
    "    datasets[i]['train'] = []\n",
    "    datasets[i]['test'] = []\n",
    "    for f in range(1,6): #for each fold\n",
    "        csv_filename = f'{data_dir}/D{i}-fold{f}-train.csv'\n",
    "        df_train = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, on_bad_lines='skip')\n",
    "        csv_filename = f'{data_dir}/D{i}-fold{f}-test.csv'\n",
    "        df_test = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, on_bad_lines='skip')\n",
    "        datasets[i]['train'].append(df_train)\n",
    "        datasets[i]['test'].append(df_test)\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc4e805-b278-46de-b411-d8f39e0cdd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling "
     ]
    }
   ],
   "source": [
    "print('Scaling ', end='')\n",
    "# Creating copies of the datasets:\n",
    "datasets_ss = copy.deepcopy(datasets)\n",
    "datasets_mms = copy.deepcopy(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75ebc15-a276-4b82-99da-be8ebddcacb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# Ignoring warnings from QuantileTransformer when number of samples is lower then 1000:\n",
    "# warnings.filterwarnings(action = \"ignore\", category=UserWarning) \n",
    "\n",
    "ss = StandardScaler()\n",
    "mms = MinMaxScaler() \n",
    "\n",
    "for i in range(1,301):\n",
    "    for fold in range(5):\n",
    "        #print(f'Dataset: {name}, fold {fold}.', end = '')\n",
    "        datasets_ss[i]['train'][fold].iloc[:,:-1] = ss.fit_transform(datasets_ss[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_ss[i]['test'][fold].iloc[:,:-1] = ss.transform(datasets_ss[i]['test'][fold].iloc[:,:-1])\n",
    "        datasets_mms[i]['train'][fold].iloc[:,:-1] = mms.fit_transform(datasets_mms[i]['train'][fold].iloc[:,:-1])\n",
    "        datasets_mms[i]['test'][fold].iloc[:,:-1] = mms.transform(datasets_mms[i]['test'][fold].iloc[:,:-1])        \n",
    "    print('.', end='') \n",
    "# Restablishing warnings:\n",
    "# warnings.filterwarnings(action = \"default\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2718834b-e2ec-41de-a64b-7e809b177b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, model_name, results_df): \n",
    "#This function was modified to deal with the different API for the GKELM\n",
    "    superset = {'SS': datasets_ss, 'MMS': datasets_mms}\n",
    "    \n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in range(1,301): #name is actually a number\n",
    "    #for name in [1]: #testing \n",
    "        print(f'\\nCurrent dataset: {name}', end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                \n",
    "                #Fit the model:\n",
    "                # For elmk, target variable must be the first (!):\n",
    "                tr_data = pd.concat([y_train, X_train], axis=1).to_numpy()\n",
    "                \n",
    "                # search for best parameter for this dataset\n",
    "                #model.search_param(tr_data, cv=\"kfold\", of=\"accuracy\", eval=10)\n",
    "                                #model.fit(X_train, y_train)\n",
    "\n",
    "                model.train(tr_data)\n",
    "                \n",
    "                # Test model:\n",
    "                # y_pred = model.predict(X_test)\n",
    "                tst_data = pd.concat([y_test, X_test], axis=1).to_numpy()\n",
    "                result = model.test(tst_data).predicted_targets.reshape(1, -1)\n",
    "                y_pred = []\n",
    "                for x in result[0]:\n",
    "                    if abs(x-0) >= abs(x-1): y_pred.append(1) # If the regressed value is closer to 1.\n",
    "                    else: y_pred.append(0) # If the regressed value is closer to 0.\n",
    "                # print('y_pred = ', y_pred)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                # recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "                # precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label=1)\n",
    "                #roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                # recall_folds.append(recall)\n",
    "                # precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                # roc_auc_folds.append(roc_auc)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       # 'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       # 'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       # 'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       # 'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       # 'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       # 'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "#                        'roc_auc_fold1' : roc_auc_folds[0], 'roc_auc_fold2' : roc_auc_folds[1], 'roc_auc_fold3' : roc_auc_folds[2], \n",
    "#                        'roc_auc_fold4' : roc_auc_folds[3], 'roc_auc_fold5' : roc_auc_folds[4], \n",
    "#                        'roc_auc_mean': np.mean(f1_folds), 'roc_auc_stddev': np.std(roc_auc_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds),\n",
    "                      }\n",
    "\n",
    "            #results_df = results_df.append(new_row, ignore_index=True) #Deprecated\n",
    "            results_df = pd.concat([results_df, pd.DataFrame.from_records([new_row])],ignore_index=True)\n",
    "\n",
    "    print('Finishing '+ model_name +', time: ', datetime.now())   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d17d18c3-5ad0-4817-8f97-23a6fc1c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           # 'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           # 'recall_mean':[], 'recall_stddev':[],\n",
    "                           # 'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           # 'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e67e02f9-9401-420a-80df-77c9f88a2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiating model:\n",
    "models = {'GKELM': elmk.ELMKernel()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9e309c2-eac9-41e9-8f32-a8d57ca25cca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GKELM, time:  2023-10-20 15:06:27.510881\n",
      "\n",
      "Current dataset: 1 SS ..... MMS .....\n",
      "Current dataset: 2 SS ..... MMS .....\n",
      "Current dataset: 3 SS ..... MMS .....\n",
      "Current dataset: 4 SS ..... MMS .....\n",
      "Current dataset: 5 SS ..... MMS .....\n",
      "Current dataset: 6 SS ..... MMS .....\n",
      "Current dataset: 7 SS ..... MMS .....\n",
      "Current dataset: 8 SS ..... MMS .....\n",
      "Current dataset: 9 SS ..... MMS .....\n",
      "Current dataset: 10 SS ..... MMS .....\n",
      "Current dataset: 11 SS ..... MMS .....\n",
      "Current dataset: 12 SS ..... MMS .....\n",
      "Current dataset: 13 SS ..... MMS .....\n",
      "Current dataset: 14 SS ..... MMS .....\n",
      "Current dataset: 15 SS ..... MMS .....\n",
      "Current dataset: 16 SS ..... MMS .....\n",
      "Current dataset: 17 SS ..... MMS .....\n",
      "Current dataset: 18 SS ..... MMS .....\n",
      "Current dataset: 19 SS ..... MMS .....\n",
      "Current dataset: 20 SS ..... MMS .....\n",
      "Current dataset: 21 SS ..... MMS .....\n",
      "Current dataset: 22 SS ..... MMS .....\n",
      "Current dataset: 23 SS ..... MMS .....\n",
      "Current dataset: 24 SS ..... MMS .....\n",
      "Current dataset: 25 SS ..... MMS .....\n",
      "Current dataset: 26 SS ..... MMS .....\n",
      "Current dataset: 27 SS ..... MMS .....\n",
      "Current dataset: 28 SS ..... MMS .....\n",
      "Current dataset: 29 SS ..... MMS .....\n",
      "Current dataset: 30 SS ..... MMS .....\n",
      "Current dataset: 31 SS ..... MMS .....\n",
      "Current dataset: 32 SS ..... MMS .....\n",
      "Current dataset: 33 SS ..... MMS .....\n",
      "Current dataset: 34 SS ..... MMS .....\n",
      "Current dataset: 35 SS ..... MMS .....\n",
      "Current dataset: 36 SS ..... MMS .....\n",
      "Current dataset: 37 SS ..... MMS .....\n",
      "Current dataset: 38 SS ..... MMS .....\n",
      "Current dataset: 39 SS ..... MMS .....\n",
      "Current dataset: 40 SS ..... MMS .....\n",
      "Current dataset: 41 SS ..... MMS .....\n",
      "Current dataset: 42 SS ..... MMS .....\n",
      "Current dataset: 43 SS ..... MMS .....\n",
      "Current dataset: 44 SS ..... MMS .....\n",
      "Current dataset: 45 SS ..... MMS .....\n",
      "Current dataset: 46 SS ..... MMS .....\n",
      "Current dataset: 47 SS ..... MMS .....\n",
      "Current dataset: 48 SS ..... MMS .....\n",
      "Current dataset: 49 SS ..... MMS .....\n",
      "Current dataset: 50 SS ..... MMS .....\n",
      "Current dataset: 51 SS ..... MMS .....\n",
      "Current dataset: 52 SS ..... MMS .....\n",
      "Current dataset: 53 SS ..... MMS .....\n",
      "Current dataset: 54 SS ..... MMS .....\n",
      "Current dataset: 55 SS ..... MMS .....\n",
      "Current dataset: 56 SS ..... MMS .....\n",
      "Current dataset: 57 SS ..... MMS .....\n",
      "Current dataset: 58 SS ..... MMS .....\n",
      "Current dataset: 59 SS ..... MMS .....\n",
      "Current dataset: 60 SS ..... MMS .....\n",
      "Current dataset: 61 SS ..... MMS .....\n",
      "Current dataset: 62 SS ..... MMS .....\n",
      "Current dataset: 63 SS ..... MMS .....\n",
      "Current dataset: 64 SS ..... MMS .....\n",
      "Current dataset: 65 SS ..... MMS .....\n",
      "Current dataset: 66 SS ..... MMS .....\n",
      "Current dataset: 67 SS ..... MMS .....\n",
      "Current dataset: 68 SS ..... MMS .....\n",
      "Current dataset: 69 SS ..... MMS .....\n",
      "Current dataset: 70 SS ..... MMS .....\n",
      "Current dataset: 71 SS ..... MMS .....\n",
      "Current dataset: 72 SS ..... MMS .....\n",
      "Current dataset: 73 SS ..... MMS .....\n",
      "Current dataset: 74 SS ..... MMS .....\n",
      "Current dataset: 75 SS ..... MMS .....\n",
      "Current dataset: 76 SS ..... MMS .....\n",
      "Current dataset: 77 SS ..... MMS .....\n",
      "Current dataset: 78 SS ..... MMS .....\n",
      "Current dataset: 79 SS ..... MMS .....\n",
      "Current dataset: 80 SS ..... MMS .....\n",
      "Current dataset: 81 SS ..... MMS .....\n",
      "Current dataset: 82 SS ..... MMS .....\n",
      "Current dataset: 83 SS ..... MMS .....\n",
      "Current dataset: 84 SS ..... MMS .....\n",
      "Current dataset: 85 SS ..... MMS .....\n",
      "Current dataset: 86 SS ..... MMS .....\n",
      "Current dataset: 87 SS ..... MMS .....\n",
      "Current dataset: 88 SS ..... MMS .....\n",
      "Current dataset: 89 SS ..... MMS .....\n",
      "Current dataset: 90 SS ..... MMS .....\n",
      "Current dataset: 91 SS ..... MMS .....\n",
      "Current dataset: 92 SS ..... MMS .....\n",
      "Current dataset: 93 SS ..... MMS .....\n",
      "Current dataset: 94 SS ..... MMS .....\n",
      "Current dataset: 95 SS ..... MMS .....\n",
      "Current dataset: 96 SS ..... MMS .....\n",
      "Current dataset: 97 SS ..... MMS .....\n",
      "Current dataset: 98 SS ..... MMS .....\n",
      "Current dataset: 99 SS ..... MMS .....\n",
      "Current dataset: 100 SS ..... MMS .....\n",
      "Current dataset: 101 SS ..... MMS .....\n",
      "Current dataset: 102 SS ..... MMS .....\n",
      "Current dataset: 103 SS ..... MMS .....\n",
      "Current dataset: 104 SS ..... MMS .....\n",
      "Current dataset: 105 SS ..... MMS .....\n",
      "Current dataset: 106 SS ..... MMS .....\n",
      "Current dataset: 107 SS ..... MMS .....\n",
      "Current dataset: 108 SS ..... MMS .....\n",
      "Current dataset: 109 SS ..... MMS .....\n",
      "Current dataset: 110 SS ..... MMS .....\n",
      "Current dataset: 111 SS ..... MMS .....\n",
      "Current dataset: 112 SS ..... MMS .....\n",
      "Current dataset: 113 SS ..... MMS .....\n",
      "Current dataset: 114 SS ..... MMS .....\n",
      "Current dataset: 115 SS ..... MMS .....\n",
      "Current dataset: 116 SS ..... MMS .....\n",
      "Current dataset: 117 SS ..... MMS .....\n",
      "Current dataset: 118 SS ..... MMS .....\n",
      "Current dataset: 119 SS ..... MMS .....\n",
      "Current dataset: 120 SS ..... MMS .....\n",
      "Current dataset: 121 SS ..... MMS .....\n",
      "Current dataset: 122 SS ..... MMS .....\n",
      "Current dataset: 123 SS ..... MMS .....\n",
      "Current dataset: 124 SS ..... MMS .....\n",
      "Current dataset: 125 SS ..... MMS .....\n",
      "Current dataset: 126 SS ..... MMS .....\n",
      "Current dataset: 127 SS ..... MMS .....\n",
      "Current dataset: 128 SS ..... MMS .....\n",
      "Current dataset: 129 SS ..... MMS .....\n",
      "Current dataset: 130 SS ..... MMS .....\n",
      "Current dataset: 131 SS ..... MMS .....\n",
      "Current dataset: 132 SS ..... MMS .....\n",
      "Current dataset: 133 SS ..... MMS .....\n",
      "Current dataset: 134 SS ..... MMS .....\n",
      "Current dataset: 135 SS ..... MMS .....\n",
      "Current dataset: 136 SS ..... MMS .....\n",
      "Current dataset: 137 SS ..... MMS .....\n",
      "Current dataset: 138 SS ..... MMS .....\n",
      "Current dataset: 139 SS ..... MMS .....\n",
      "Current dataset: 140 SS ..... MMS .....\n",
      "Current dataset: 141 SS ..... MMS .....\n",
      "Current dataset: 142 SS ..... MMS .....\n",
      "Current dataset: 143 SS ..... MMS .....\n",
      "Current dataset: 144 SS ..... MMS .....\n",
      "Current dataset: 145 SS ..... MMS .....\n",
      "Current dataset: 146 SS ..... MMS .....\n",
      "Current dataset: 147 SS ..... MMS .....\n",
      "Current dataset: 148 SS ..... MMS .....\n",
      "Current dataset: 149 SS ..... MMS .....\n",
      "Current dataset: 150 SS ..... MMS .....\n",
      "Current dataset: 151 SS ..... MMS .....\n",
      "Current dataset: 152 SS ..... MMS .....\n",
      "Current dataset: 153 SS ..... MMS .....\n",
      "Current dataset: 154 SS ..... MMS .....\n",
      "Current dataset: 155 SS ..... MMS .....\n",
      "Current dataset: 156 SS ..... MMS .....\n",
      "Current dataset: 157 SS ..... MMS .....\n",
      "Current dataset: 158 SS ..... MMS .....\n",
      "Current dataset: 159 SS ..... MMS .....\n",
      "Current dataset: 160 SS ..... MMS .....\n",
      "Current dataset: 161 SS ..... MMS .....\n",
      "Current dataset: 162 SS ..... MMS .....\n",
      "Current dataset: 163 SS ..... MMS .....\n",
      "Current dataset: 164 SS ..... MMS .....\n",
      "Current dataset: 165 SS ..... MMS .....\n",
      "Current dataset: 166 SS ..... MMS .....\n",
      "Current dataset: 167 SS ..... MMS .....\n",
      "Current dataset: 168 SS ..... MMS .....\n",
      "Current dataset: 169 SS ..... MMS .....\n",
      "Current dataset: 170 SS ..... MMS .....\n",
      "Current dataset: 171 SS ..... MMS .....\n",
      "Current dataset: 172 SS ..... MMS .....\n",
      "Current dataset: 173 SS ..... MMS .....\n",
      "Current dataset: 174 SS ..... MMS .....\n",
      "Current dataset: 175 SS ..... MMS .....\n",
      "Current dataset: 176 SS ..... MMS .....\n",
      "Current dataset: 177 SS ..... MMS .....\n",
      "Current dataset: 178 SS ..... MMS .....\n",
      "Current dataset: 179 SS ..... MMS .....\n",
      "Current dataset: 180 SS ..... MMS .....\n",
      "Current dataset: 181 SS ..... MMS .....\n",
      "Current dataset: 182 SS ..... MMS .....\n",
      "Current dataset: 183 SS ..... MMS .....\n",
      "Current dataset: 184 SS ..... MMS .....\n",
      "Current dataset: 185 SS ..... MMS .....\n",
      "Current dataset: 186 SS ..... MMS .....\n",
      "Current dataset: 187 SS ..... MMS .....\n",
      "Current dataset: 188 SS ..... MMS .....\n",
      "Current dataset: 189 SS ..... MMS .....\n",
      "Current dataset: 190 SS ..... MMS .....\n",
      "Current dataset: 191 SS ..... MMS .....\n",
      "Current dataset: 192 SS ..... MMS .....\n",
      "Current dataset: 193 SS ..... MMS .....\n",
      "Current dataset: 194 SS ..... MMS .....\n",
      "Current dataset: 195 SS ..... MMS .....\n",
      "Current dataset: 196 SS ..... MMS .....\n",
      "Current dataset: 197 SS ..... MMS .....\n",
      "Current dataset: 198 SS ..... MMS .....\n",
      "Current dataset: 199 SS ..... MMS .....\n",
      "Current dataset: 200 SS ..... MMS .....\n",
      "Current dataset: 201 SS ..... MMS .....\n",
      "Current dataset: 202 SS ..... MMS .....\n",
      "Current dataset: 203 SS ..... MMS .....\n",
      "Current dataset: 204 SS ..... MMS .....\n",
      "Current dataset: 205 SS ..... MMS .....\n",
      "Current dataset: 206 SS ..... MMS .....\n",
      "Current dataset: 207 SS ..... MMS .....\n",
      "Current dataset: 208 SS ..... MMS .....\n",
      "Current dataset: 209 SS ..... MMS .....\n",
      "Current dataset: 210 SS ..... MMS .....\n",
      "Current dataset: 211 SS ..... MMS .....\n",
      "Current dataset: 212 SS ..... MMS .....\n",
      "Current dataset: 213 SS ..... MMS .....\n",
      "Current dataset: 214 SS ..... MMS .....\n",
      "Current dataset: 215 SS ..... MMS .....\n",
      "Current dataset: 216 SS ..... MMS .....\n",
      "Current dataset: 217 SS ..... MMS .....\n",
      "Current dataset: 218 SS ..... MMS .....\n",
      "Current dataset: 219 SS ..... MMS .....\n",
      "Current dataset: 220 SS ..... MMS .....\n",
      "Current dataset: 221 SS ..... MMS .....\n",
      "Current dataset: 222 SS ..... MMS .....\n",
      "Current dataset: 223 SS ..... MMS .....\n",
      "Current dataset: 224 SS ..... MMS .....\n",
      "Current dataset: 225 SS ..... MMS .....\n",
      "Current dataset: 226 SS ..... MMS .....\n",
      "Current dataset: 227 SS ..... MMS .....\n",
      "Current dataset: 228 SS ..... MMS .....\n",
      "Current dataset: 229 SS ..... MMS .....\n",
      "Current dataset: 230 SS ..... MMS .....\n",
      "Current dataset: 231 SS ..... MMS .....\n",
      "Current dataset: 232 SS ..... MMS .....\n",
      "Current dataset: 233 SS ..... MMS .....\n",
      "Current dataset: 234 SS ..... MMS .....\n",
      "Current dataset: 235 SS ..... MMS .....\n",
      "Current dataset: 236 SS ..... MMS .....\n",
      "Current dataset: 237 SS ..... MMS .....\n",
      "Current dataset: 238 SS ..... MMS .....\n",
      "Current dataset: 239 SS ..... MMS .....\n",
      "Current dataset: 240 SS ..... MMS .....\n",
      "Current dataset: 241 SS ..... MMS .....\n",
      "Current dataset: 242 SS ..... MMS .....\n",
      "Current dataset: 243 SS ..... MMS .....\n",
      "Current dataset: 244 SS ..... MMS .....\n",
      "Current dataset: 245 SS ..... MMS .....\n",
      "Current dataset: 246 SS ..... MMS .....\n",
      "Current dataset: 247 SS ..... MMS .....\n",
      "Current dataset: 248 SS ..... MMS .....\n",
      "Current dataset: 249 SS ..... MMS .....\n",
      "Current dataset: 250 SS ..... MMS .....\n",
      "Current dataset: 251 SS ..... MMS .....\n",
      "Current dataset: 252 SS ..... MMS .....\n",
      "Current dataset: 253 SS ..... MMS .....\n",
      "Current dataset: 254 SS ..... MMS .....\n",
      "Current dataset: 255 SS ..... MMS .....\n",
      "Current dataset: 256 SS ..... MMS .....\n",
      "Current dataset: 257 SS ..... MMS .....\n",
      "Current dataset: 258 SS ..... MMS .....\n",
      "Current dataset: 259 SS ..... MMS .....\n",
      "Current dataset: 260 SS ..... MMS .....\n",
      "Current dataset: 261 SS ..... MMS .....\n",
      "Current dataset: 262 SS ..... MMS .....\n",
      "Current dataset: 263 SS ..... MMS .....\n",
      "Current dataset: 264 SS ..... MMS .....\n",
      "Current dataset: 265 SS ..... MMS .....\n",
      "Current dataset: 266 SS ..... MMS .....\n",
      "Current dataset: 267 SS ..... MMS .....\n",
      "Current dataset: 268 SS ..... MMS .....\n",
      "Current dataset: 269 SS ..... MMS .....\n",
      "Current dataset: 270 SS ..... MMS .....\n",
      "Current dataset: 271 SS ..... MMS .....\n",
      "Current dataset: 272 SS ..... MMS .....\n",
      "Current dataset: 273 SS ..... MMS .....\n",
      "Current dataset: 274 SS ..... MMS .....\n",
      "Current dataset: 275 SS ..... MMS .....\n",
      "Current dataset: 276 SS ..... MMS .....\n",
      "Current dataset: 277 SS ..... MMS .....\n",
      "Current dataset: 278 SS ..... MMS .....\n",
      "Current dataset: 279 SS ..... MMS .....\n",
      "Current dataset: 280 SS ..... MMS .....\n",
      "Current dataset: 281 SS ..... MMS .....\n",
      "Current dataset: 282 SS ..... MMS .....\n",
      "Current dataset: 283 SS ..... MMS .....\n",
      "Current dataset: 284 SS ..... MMS .....\n",
      "Current dataset: 285 SS ..... MMS .....\n",
      "Current dataset: 286 SS ..... MMS .....\n",
      "Current dataset: 287 SS ..... MMS .....\n",
      "Current dataset: 288 SS ..... MMS .....\n",
      "Current dataset: 289 SS ..... MMS .....\n",
      "Current dataset: 290 SS ..... MMS .....\n",
      "Current dataset: 291 SS ..... MMS .....\n",
      "Current dataset: 292 SS ..... MMS .....\n",
      "Current dataset: 293 SS ..... MMS .....\n",
      "Current dataset: 294 SS ..... MMS .....\n",
      "Current dataset: 295 SS ..... MMS .....\n",
      "Current dataset: 296 SS ..... MMS .....\n",
      "Current dataset: 297 SS ..... MMS .....\n",
      "Current dataset: 298 SS ..... MMS .....\n",
      "Current dataset: 299 SS ..... MMS .....\n",
      "Current dataset: 300 SS ..... MMS .....Finishing GKELM, time:  2023-10-20 15:07:09.558234\n"
     ]
    }
   ],
   "source": [
    "# Running models:\n",
    "for name,model in models.items():\n",
    "        results_df = run_model(model, name, results_df)\n",
    "results_df.to_csv('results_ST_perfs_GKELM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b755b5b0-3cb9-4f87-9e3c-386370604ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Scaling technique</th>\n",
       "      <th>Model</th>\n",
       "      <th>acc_fold1</th>\n",
       "      <th>acc_fold2</th>\n",
       "      <th>acc_fold3</th>\n",
       "      <th>acc_fold4</th>\n",
       "      <th>acc_fold5</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_stddev</th>\n",
       "      <th>...</th>\n",
       "      <th>f1_fold5</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_stddev</th>\n",
       "      <th>gmean_fold1</th>\n",
       "      <th>gmean_fold2</th>\n",
       "      <th>gmean_fold3</th>\n",
       "      <th>gmean_fold4</th>\n",
       "      <th>gmean_fold5</th>\n",
       "      <th>gmean_mean</th>\n",
       "      <th>gmean_stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.475082</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.045659</td>\n",
       "      <td>0.468353</td>\n",
       "      <td>0.490170</td>\n",
       "      <td>0.498888</td>\n",
       "      <td>0.428174</td>\n",
       "      <td>0.461880</td>\n",
       "      <td>0.469493</td>\n",
       "      <td>0.024731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MMS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.468470</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.417401</td>\n",
       "      <td>0.036774</td>\n",
       "      <td>0.439941</td>\n",
       "      <td>0.483314</td>\n",
       "      <td>0.449691</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.453475</td>\n",
       "      <td>0.015273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.640796</td>\n",
       "      <td>0.045854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.603944</td>\n",
       "      <td>0.061955</td>\n",
       "      <td>0.617914</td>\n",
       "      <td>0.685913</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.694949</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.049740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MMS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.627937</td>\n",
       "      <td>0.048182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.499010</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>0.542720</td>\n",
       "      <td>0.627922</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.488504</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>0.571079</td>\n",
       "      <td>0.050444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>0.070734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.382179</td>\n",
       "      <td>0.094986</td>\n",
       "      <td>0.405244</td>\n",
       "      <td>0.369936</td>\n",
       "      <td>0.279508</td>\n",
       "      <td>0.478033</td>\n",
       "      <td>0.315909</td>\n",
       "      <td>0.369726</td>\n",
       "      <td>0.069322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>298.0</td>\n",
       "      <td>MMS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.578033</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.639569</td>\n",
       "      <td>0.053380</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.633866</td>\n",
       "      <td>0.577672</td>\n",
       "      <td>0.436862</td>\n",
       "      <td>0.511039</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>0.068200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>299.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.087178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.432965</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.514242</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.416333</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.445102</td>\n",
       "      <td>0.086253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>299.0</td>\n",
       "      <td>MMS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.068313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.418514</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.292499</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>0.442217</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>0.429604</td>\n",
       "      <td>0.070681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>300.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.513005</td>\n",
       "      <td>0.045008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.300480</td>\n",
       "      <td>0.058149</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.412710</td>\n",
       "      <td>0.322603</td>\n",
       "      <td>0.426763</td>\n",
       "      <td>0.456229</td>\n",
       "      <td>0.413594</td>\n",
       "      <td>0.048109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>300.0</td>\n",
       "      <td>MMS</td>\n",
       "      <td>GKELM</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.562896</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053814</td>\n",
       "      <td>0.107628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset Scaling technique  Model  acc_fold1  acc_fold2  acc_fold3  \\\n",
       "0        1.0                SS  GKELM   0.475410   0.500000   0.500000   \n",
       "1        1.0               MMS  GKELM   0.459016   0.516667   0.450000   \n",
       "2        2.0                SS  GKELM   0.617021   0.695652   0.586957   \n",
       "3        2.0               MMS  GKELM   0.574468   0.695652   0.608696   \n",
       "4        3.0                SS  GKELM   0.406250   0.375000   0.281250   \n",
       "..       ...               ...    ...        ...        ...        ...   \n",
       "595    298.0               MMS  GKELM   0.590164   0.650000   0.600000   \n",
       "596    299.0                SS  GKELM   0.300000   0.516667   0.450000   \n",
       "597    299.0               MMS  GKELM   0.300000   0.483333   0.450000   \n",
       "598    300.0                SS  GKELM   0.508197   0.590164   0.450000   \n",
       "599    300.0               MMS  GKELM   0.557377   0.573770   0.550000   \n",
       "\n",
       "     acc_fold4  acc_fold5  acc_mean  acc_stddev  ...  f1_fold5   f1_mean  \\\n",
       "0     0.433333   0.466667  0.475082    0.024721  ...  0.500000  0.456400   \n",
       "1     0.466667   0.450000  0.468470    0.024891  ...  0.476190  0.417401   \n",
       "2     0.608696   0.695652  0.640796    0.045854  ...  0.681818  0.603944   \n",
       "3     0.586957   0.673913  0.627937    0.048182  ...  0.545455  0.499010   \n",
       "4     0.484375   0.317460  0.372867    0.070734  ...  0.295082  0.382179   \n",
       "..         ...        ...       ...         ...  ...       ...       ...   \n",
       "595   0.466667   0.583333  0.578033    0.060398  ...  0.675325  0.639569   \n",
       "596   0.416667   0.550000  0.446667    0.087178  ...  0.526316  0.432965   \n",
       "597   0.450000   0.483333  0.433333    0.068313  ...  0.474576  0.418514   \n",
       "598   0.500000   0.516667  0.513005    0.045008  ...  0.355556  0.300480   \n",
       "599   0.566667   0.566667  0.562896    0.008288  ...  0.000000  0.026667   \n",
       "\n",
       "     f1_stddev  gmean_fold1  gmean_fold2  gmean_fold3  gmean_fold4  \\\n",
       "0     0.045659     0.468353     0.490170     0.498888     0.428174   \n",
       "1     0.036774     0.439941     0.483314     0.449691     0.447214   \n",
       "2     0.061955     0.617914     0.685913     0.577350     0.583874   \n",
       "3     0.063403     0.542720     0.627922     0.583874     0.488504   \n",
       "4     0.094986     0.405244     0.369936     0.279508     0.478033   \n",
       "..         ...          ...          ...          ...          ...   \n",
       "595   0.053380     0.583874     0.633866     0.577672     0.436862   \n",
       "596   0.077429     0.300000     0.514242     0.447214     0.416333   \n",
       "597   0.090090     0.292499     0.483046     0.442217     0.447214   \n",
       "598   0.058149     0.449664     0.412710     0.322603     0.426763   \n",
       "599   0.053333     0.000000     0.000000     0.000000     0.269069   \n",
       "\n",
       "     gmean_fold5  gmean_mean  gmean_stddev  \n",
       "0       0.461880    0.469493      0.024731  \n",
       "1       0.447214    0.453475      0.015273  \n",
       "2       0.694949    0.632000      0.049740  \n",
       "3       0.612372    0.571079      0.050444  \n",
       "4       0.315909    0.369726      0.069322  \n",
       "..           ...         ...           ...  \n",
       "595     0.511039    0.548663      0.068200  \n",
       "596     0.547723    0.445102      0.086253  \n",
       "597     0.483046    0.429604      0.070681  \n",
       "598     0.456229    0.413594      0.048109  \n",
       "599     0.000000    0.053814      0.107628  \n",
       "\n",
       "[600 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_df = pd.read_csv('results_ST_perfs_GKELM.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453af2f5-2dcd-4588-9bcd-c7a1c64c13bf",
   "metadata": {},
   "source": [
    "# Creating Meta-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb38cc-693a-428b-a4e0-4361d514e9d0",
   "metadata": {},
   "source": [
    "## Creating target attribute (Best_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a87a3524-e9d9-4d96-bdc6-e9b421582970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/5l9b38356rg068nt7zvgjm_00000gn/T/ipykernel_1082/428406812.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  perfs['ds_name'] = perfs['Dataset'].apply(lambda x: f'D{int(x)}')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>Scaling technique</th>\n",
       "      <th>f1_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.456400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>MMS</td>\n",
       "      <td>0.417401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.603944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2</td>\n",
       "      <td>MMS</td>\n",
       "      <td>0.499010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.382179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>D298</td>\n",
       "      <td>MMS</td>\n",
       "      <td>0.639569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>D299</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.432965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>D299</td>\n",
       "      <td>MMS</td>\n",
       "      <td>0.418514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>D300</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.300480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>D300</td>\n",
       "      <td>MMS</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ds_name Scaling technique   f1_mean\n",
       "0        D1                SS  0.456400\n",
       "1        D1               MMS  0.417401\n",
       "2        D2                SS  0.603944\n",
       "3        D2               MMS  0.499010\n",
       "4        D3                SS  0.382179\n",
       "..      ...               ...       ...\n",
       "595    D298               MMS  0.639569\n",
       "596    D299                SS  0.432965\n",
       "597    D299               MMS  0.418514\n",
       "598    D300                SS  0.300480\n",
       "599    D300               MMS  0.026667\n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfs = results_df[['Dataset', 'Scaling technique', 'f1_mean']]\n",
    "perfs['ds_name'] = perfs['Dataset'].apply(lambda x: f'D{int(x)}')\n",
    "perfs = perfs[['ds_name', 'Scaling technique', 'f1_mean']]\n",
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6bd4e832-fc74-4f6c-8f79-c3410bb784b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = list(perfs.ds_name.unique())\n",
    "meta_dataset_dict = {'ds_name':[], 'SS':[], 'MMS':[], 'best_st':[] #, 'best_sts':[]\n",
    "                    }\n",
    "for ds_name in ds_names:\n",
    "    perfs_filtered_by_ds = perfs[perfs['ds_name']==ds_name]\n",
    "    max_perf = perfs_filtered_by_ds.f1_mean.max()\n",
    "    best_sts = perfs_filtered_by_ds[perfs_filtered_by_ds['f1_mean'] == max_perf]['Scaling technique'].values\n",
    "    best_st = best_sts[0] #Sometimes, both STs attain max perf, we will just pick the first, as we did in our paper.\n",
    "    meta_dataset_dict['ds_name'].append(ds_name)\n",
    "    meta_dataset_dict['best_st'].append(best_st)\n",
    "    for st in ['SS', 'MMS']:\n",
    "        row_for_this_st = perfs_filtered_by_ds['Scaling technique'] == st\n",
    "        perf_for_this_st = perfs_filtered_by_ds[row_for_this_st].f1_mean.values[0]\n",
    "        meta_dataset_dict[st].append(perf_for_this_st)\n",
    "    #meta_dataset_dict['best_sts'].append(best_sts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d86c24c3-16ce-4830-9fae-2d5771ea4849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>SS</th>\n",
       "      <th>MMS</th>\n",
       "      <th>best_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.417401</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>0.603944</td>\n",
       "      <td>0.499010</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>0.382179</td>\n",
       "      <td>0.459705</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>0.490649</td>\n",
       "      <td>0.547206</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>0.510446</td>\n",
       "      <td>0.599733</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>D296</td>\n",
       "      <td>0.547996</td>\n",
       "      <td>0.452201</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>D297</td>\n",
       "      <td>0.683706</td>\n",
       "      <td>0.650371</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>D298</td>\n",
       "      <td>0.607885</td>\n",
       "      <td>0.639569</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>D299</td>\n",
       "      <td>0.432965</td>\n",
       "      <td>0.418514</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>D300</td>\n",
       "      <td>0.300480</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ds_name        SS       MMS best_st\n",
       "0        D1  0.456400  0.417401      SS\n",
       "1        D2  0.603944  0.499010      SS\n",
       "2        D3  0.382179  0.459705     MMS\n",
       "3        D4  0.490649  0.547206     MMS\n",
       "4        D5  0.510446  0.599733     MMS\n",
       "..      ...       ...       ...     ...\n",
       "295    D296  0.547996  0.452201      SS\n",
       "296    D297  0.683706  0.650371      SS\n",
       "297    D298  0.607885  0.639569     MMS\n",
       "298    D299  0.432965  0.418514      SS\n",
       "299    D300  0.300480  0.026667      SS\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset = pd.DataFrame(meta_dataset_dict)\n",
    "meta_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a5c19-a87b-4ab4-8aa2-30bc6c0c3870",
   "metadata": {},
   "source": [
    "## Adding the meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "88036187-6e38-4c45-954c-7f2f01a9d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset = pd.concat([meta_dataset[meta_dataset.columns[:1]], mfs, meta_dataset[meta_dataset.columns[1:]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b790929f-9d53-4660-966b-b75722548300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_name</th>\n",
       "      <th>f1.mean</th>\n",
       "      <th>f2.mean</th>\n",
       "      <th>f3.mean</th>\n",
       "      <th>n2.mean</th>\n",
       "      <th>n3.mean</th>\n",
       "      <th>t1.mean</th>\n",
       "      <th>t2</th>\n",
       "      <th>density</th>\n",
       "      <th>n4.mean</th>\n",
       "      <th>l1.mean</th>\n",
       "      <th>l2.mean</th>\n",
       "      <th>l3.mean</th>\n",
       "      <th>SS</th>\n",
       "      <th>MMS</th>\n",
       "      <th>best_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>0.997618</td>\n",
       "      <td>0.216065</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.503851</td>\n",
       "      <td>0.574751</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182724</td>\n",
       "      <td>0.177843</td>\n",
       "      <td>0.455150</td>\n",
       "      <td>0.421927</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.417401</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>0.966098</td>\n",
       "      <td>0.193836</td>\n",
       "      <td>0.965368</td>\n",
       "      <td>0.506958</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>0.989046</td>\n",
       "      <td>0.307359</td>\n",
       "      <td>0.175905</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.251082</td>\n",
       "      <td>0.603944</td>\n",
       "      <td>0.499010</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>0.998351</td>\n",
       "      <td>0.140620</td>\n",
       "      <td>0.984326</td>\n",
       "      <td>0.506327</td>\n",
       "      <td>0.567398</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.062696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.445141</td>\n",
       "      <td>0.388715</td>\n",
       "      <td>0.382179</td>\n",
       "      <td>0.459705</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.966777</td>\n",
       "      <td>0.502377</td>\n",
       "      <td>0.554817</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205980</td>\n",
       "      <td>0.182535</td>\n",
       "      <td>0.388704</td>\n",
       "      <td>0.358804</td>\n",
       "      <td>0.490649</td>\n",
       "      <td>0.547206</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.505203</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.188478</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.510446</td>\n",
       "      <td>0.599733</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>D296</td>\n",
       "      <td>0.968520</td>\n",
       "      <td>0.069950</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.502993</td>\n",
       "      <td>0.508547</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.989032</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.163246</td>\n",
       "      <td>0.354701</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.547996</td>\n",
       "      <td>0.452201</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>D297</td>\n",
       "      <td>0.968030</td>\n",
       "      <td>0.056096</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>0.498197</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.158659</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.683706</td>\n",
       "      <td>0.650371</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>D298</td>\n",
       "      <td>0.992193</td>\n",
       "      <td>0.071053</td>\n",
       "      <td>0.870432</td>\n",
       "      <td>0.512317</td>\n",
       "      <td>0.707641</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176080</td>\n",
       "      <td>0.172496</td>\n",
       "      <td>0.355482</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.607885</td>\n",
       "      <td>0.639569</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>D299</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.502802</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.206342</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.432965</td>\n",
       "      <td>0.418514</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>D300</td>\n",
       "      <td>0.997032</td>\n",
       "      <td>0.040362</td>\n",
       "      <td>0.930464</td>\n",
       "      <td>0.506703</td>\n",
       "      <td>0.612583</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182119</td>\n",
       "      <td>0.188546</td>\n",
       "      <td>0.367550</td>\n",
       "      <td>0.367550</td>\n",
       "      <td>0.300480</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ds_name   f1.mean   f2.mean   f3.mean   n2.mean   n3.mean   t1.mean  \\\n",
       "0        D1  0.997618  0.216065  0.976744  0.503851  0.574751  0.006667   \n",
       "1        D2  0.966098  0.193836  0.965368  0.506958  0.528139  0.006536   \n",
       "2        D3  0.998351  0.140620  0.984326  0.506327  0.567398  0.007143   \n",
       "3        D4  0.997004  0.052404  0.966777  0.502377  0.554817  0.007576   \n",
       "4        D5  0.997819  0.090321  0.970000  0.505203  0.580000  0.007752   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "295    D296  0.968520  0.069950  0.931624  0.502993  0.508547  0.018868   \n",
       "296    D297  0.968030  0.056096  0.900433  0.498197  0.528139  0.008929   \n",
       "297    D298  0.992193  0.071053  0.870432  0.512317  0.707641  0.005236   \n",
       "298    D299  0.998167  0.011849  0.660000  0.502802  0.536667  0.006849   \n",
       "299    D300  0.997032  0.040362  0.930464  0.506703  0.612583  0.006536   \n",
       "\n",
       "           t2   density   n4.mean   l1.mean   l2.mean   l3.mean        SS  \\\n",
       "0    0.066445  1.000000  0.182724  0.177843  0.455150  0.421927  0.456400   \n",
       "1    0.034632  0.989046  0.307359  0.175905  0.311688  0.251082  0.603944   \n",
       "2    0.062696  1.000000  0.172414  0.186916  0.445141  0.388715  0.382179   \n",
       "3    0.066445  1.000000  0.205980  0.182535  0.388704  0.358804  0.490649   \n",
       "4    0.066667  1.000000  0.203333  0.188478  0.390000  0.463333  0.510446   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  0.034188  0.989032  0.380342  0.163246  0.354701  0.256410  0.547996   \n",
       "296  0.034632  0.992208  0.311688  0.158659  0.303030  0.242424  0.683706   \n",
       "297  0.066445  1.000000  0.176080  0.172496  0.355482  0.285714  0.607885   \n",
       "298  0.066667  1.000000  0.170000  0.206342  0.390000  0.360000  0.432965   \n",
       "299  0.066225  1.000000  0.182119  0.188546  0.367550  0.367550  0.300480   \n",
       "\n",
       "          MMS best_st  \n",
       "0    0.417401      SS  \n",
       "1    0.499010      SS  \n",
       "2    0.459705     MMS  \n",
       "3    0.547206     MMS  \n",
       "4    0.599733     MMS  \n",
       "..        ...     ...  \n",
       "295  0.452201      SS  \n",
       "296  0.650371      SS  \n",
       "297  0.639569     MMS  \n",
       "298  0.418514      SS  \n",
       "299  0.026667      SS  \n",
       "\n",
       "[300 rows x 16 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c65aa-5a9b-4fcb-b465-97ec9c530853",
   "metadata": {},
   "source": [
    "# Train the meta-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c25941-b472-43a5-833b-d3902255108e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we need to train/test a GKELM meta-model. We will do it with Leave One Out Cross Validation - LOOCV (as we did in our Meta-scaler paper). We are interested in the base level classification performance of the same 12 base classifiers used in our paper, attained with the recommended ST, so that we can compare that with the results of our paper (Meta-scaler). Notice that while the GKELM will be trained and tested on the meta-dataset constructed in the previews section (the one with just two STs) the ground truth will come from the meta-dataset used in our paper, where we used 12 base models and six STs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e2ca6008-4746-4879-81a1-3b669c15300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training metamodel with GKELM:\n",
      "............................................................................................................................................................................................................................................................................................................\n",
      "Training time: 1.6102496450330364 seconds.\n",
      "Testing time: 0.024362957999983337 seconds.\n",
      "CPU times: user 24.7 s, sys: 3.87 s, total: 28.6 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_time = 0\n",
    "testing_time = 0\n",
    "\n",
    "print(f'\\nTraining metamodel with GKELM:')\n",
    "df = meta_dataset.copy() # Using the meta-dataset that we built in this notebook.\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Separating X and y.\n",
    "X = df.iloc[:, 1:-3] # Just the metafeatures.\n",
    "y = df.iloc[:,-1] # Just the best ST.\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set folds, \n",
    "# according to Leave One Out Cross Validation:\n",
    "loo = LeaveOneOut()\n",
    "y_pred = list()\n",
    "for train_index, test_index in loo.split(X):\n",
    "    current_ds = df['ds_name'].iloc[test_index].values[0]\n",
    "    #print(f'Test index is {test_index}, corresponding to DS {current_ds}.')\n",
    "    print('.', end='')\n",
    "    # Separating training and test sets:\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # Filling missing values with a KNN imputer.  Each sample’s missing values are imputed\n",
    "    # using the mean value from n_neighbors nearest neighbors found in the training set. \n",
    "    imputer = KNNImputer(n_neighbors=2)\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "\n",
    "    # The above method returns a nd.array, so here we rebuild the DataFrame:\n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns) \n",
    "    X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "    \n",
    "    # Feature Scaling (Not needed if using a tree based meta-model)\n",
    "    sc = MinMaxScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # The above method returns a nd.array, so here we rebuild the DataFrame:\n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns) \n",
    "    X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "    \n",
    "    # Encoding class labes as 0s and 1s:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_train = pd.Series(y_train, name='best_st')\n",
    "    y_test = le.transform(y_test)\n",
    "    y_test = pd.Series(y_test, name='best_st')\n",
    "    \n",
    "    meta_model = elmk.ELMKernel()\n",
    "    #Fit the meta-model:\n",
    "    # For elmk, target variable must be the first (!):\n",
    "    \n",
    "    tr_data = pd.concat([y_train, X_train], axis=1).to_numpy()\n",
    "    tic = time.perf_counter()\n",
    "    meta_model.train(tr_data)\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    training_time += toc-tic      \n",
    "    \n",
    "    # Test meta_model:\n",
    "    tst_data = pd.concat([y_test, X_test], axis=1).to_numpy()\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    result = meta_model.test(tst_data).predicted_targets.reshape(1, -1)\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    testing_time += toc-tic\n",
    "    \n",
    "    # Save prediction:\n",
    "    x = result[0][0]\n",
    "    if abs(x-0) >= abs(x-1): y_pred.append(1) # If the regressed value is closer to 1.\n",
    "    else: y_pred.append(0) # If the regressed value is closer to 0.\n",
    "\n",
    "\n",
    "print(f'\\nTraining time: {training_time} seconds.')   \n",
    "print(f'Testing time: {testing_time} seconds.')       \n",
    "computing_times = {'Testing': testing_time, 'Training': training_time, \n",
    "                   'Total': testing_time+training_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f106a35-5880-44b3-a029-51ab954635b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c18147da-442c-4602-8b89-1177e047614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-model performance on GKELM meta-dataset: F1 = 0.6347513219821554, acc = 0.7766666666666666\n"
     ]
    }
   ],
   "source": [
    "# If wanted to know the meta-model performance in this meta-dataset, we would do:\n",
    "acc = accuracy_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "print(f'Meta-model performance on GKELM meta-dataset: F1 = {f1}, acc = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a683b-45b7-401b-ab82-29ffd4527272",
   "metadata": {},
   "source": [
    "# Assess base level performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc408b-bef5-4b7b-8126-f43e21192217",
   "metadata": {},
   "source": [
    "We want to know how Jain's approach perform (in terms of base-model performance, measured with F1) for each one of the 12 base models used in our paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1cf7343f-2fbf-4bec-88c7-9f8e91c5f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the meta-dataset from our paper:\n",
    "our_meta_dataset = pd.read_csv('../metafeat_pymfe+imbcol_and_ST_perform_for_pairs_of_dataset_and_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f00c8400-e5f3-4f7a-8d6b-c208102ecda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>attr_conc.mean</th>\n",
       "      <th>attr_ent.mean</th>\n",
       "      <th>attr_to_inst</th>\n",
       "      <th>best_node.mean</th>\n",
       "      <th>best_node.mean.relative</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>can_cor.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>linearity.class.L3_partial.1</th>\n",
       "      <th>NS</th>\n",
       "      <th>SS</th>\n",
       "      <th>MMS</th>\n",
       "      <th>MAS</th>\n",
       "      <th>RS</th>\n",
       "      <th>QT</th>\n",
       "      <th>Max_F1_perf</th>\n",
       "      <th>Best_STs</th>\n",
       "      <th>Best_ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>2.584913</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.494839</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448505</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>0.466025</td>\n",
       "      <td>0.394689</td>\n",
       "      <td>0.303649</td>\n",
       "      <td>0.449671</td>\n",
       "      <td>0.451235</td>\n",
       "      <td>0.466025</td>\n",
       "      <td>['SS']</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLVQ</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>2.584913</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.494839</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448505</td>\n",
       "      <td>0.434862</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>0.418003</td>\n",
       "      <td>0.445430</td>\n",
       "      <td>0.469747</td>\n",
       "      <td>0.487364</td>\n",
       "      <td>0.487364</td>\n",
       "      <td>['QT']</td>\n",
       "      <td>QT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>2.584913</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.494839</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448505</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.474876</td>\n",
       "      <td>0.384721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484660</td>\n",
       "      <td>0.441929</td>\n",
       "      <td>0.484660</td>\n",
       "      <td>['RS']</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNORAE</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>2.584913</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.494839</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448505</td>\n",
       "      <td>0.435348</td>\n",
       "      <td>0.447054</td>\n",
       "      <td>0.492395</td>\n",
       "      <td>0.450039</td>\n",
       "      <td>0.432771</td>\n",
       "      <td>0.413654</td>\n",
       "      <td>0.492395</td>\n",
       "      <td>['MMS']</td>\n",
       "      <td>MMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNORAU</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>2.584913</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.494839</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448505</td>\n",
       "      <td>0.443713</td>\n",
       "      <td>0.468347</td>\n",
       "      <td>0.487077</td>\n",
       "      <td>0.432025</td>\n",
       "      <td>0.478051</td>\n",
       "      <td>0.505159</td>\n",
       "      <td>0.505159</td>\n",
       "      <td>['QT']</td>\n",
       "      <td>QT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>MLP</td>\n",
       "      <td>D300</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>2.584899</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.986003</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572848</td>\n",
       "      <td>0.601871</td>\n",
       "      <td>0.431757</td>\n",
       "      <td>0.601871</td>\n",
       "      <td>0.601871</td>\n",
       "      <td>0.438325</td>\n",
       "      <td>0.415073</td>\n",
       "      <td>0.601871</td>\n",
       "      <td>['NS' 'MMS' 'MAS']</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>OLA</td>\n",
       "      <td>D300</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>2.584899</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.986003</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572848</td>\n",
       "      <td>0.414099</td>\n",
       "      <td>0.445926</td>\n",
       "      <td>0.386136</td>\n",
       "      <td>0.446185</td>\n",
       "      <td>0.376316</td>\n",
       "      <td>0.497744</td>\n",
       "      <td>0.497744</td>\n",
       "      <td>['QT']</td>\n",
       "      <td>QT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>Percep</td>\n",
       "      <td>D300</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>2.584899</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.986003</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572848</td>\n",
       "      <td>0.265806</td>\n",
       "      <td>0.434663</td>\n",
       "      <td>0.237405</td>\n",
       "      <td>0.267137</td>\n",
       "      <td>0.377495</td>\n",
       "      <td>0.421451</td>\n",
       "      <td>0.434663</td>\n",
       "      <td>['SS']</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>D300</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>2.584899</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.986003</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572848</td>\n",
       "      <td>0.186589</td>\n",
       "      <td>0.190331</td>\n",
       "      <td>0.201437</td>\n",
       "      <td>0.179149</td>\n",
       "      <td>0.217621</td>\n",
       "      <td>0.202262</td>\n",
       "      <td>0.217621</td>\n",
       "      <td>['RS']</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>SVM_lin</td>\n",
       "      <td>D300</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>2.584899</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.986003</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572848</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.347853</td>\n",
       "      <td>0.121659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326279</td>\n",
       "      <td>0.332856</td>\n",
       "      <td>0.347853</td>\n",
       "      <td>['SS']</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Dataset  attr_conc.mean  attr_ent.mean  attr_to_inst  \\\n",
       "0     Bagging      D1        0.019398       2.584913      0.066445   \n",
       "1        GLVQ      D1        0.019398       2.584913      0.066445   \n",
       "2          GP      D1        0.019398       2.584913      0.066445   \n",
       "3      KNORAE      D1        0.019398       2.584913      0.066445   \n",
       "4      KNORAU      D1        0.019398       2.584913      0.066445   \n",
       "...       ...     ...             ...            ...           ...   \n",
       "3595      MLP    D300        0.019184       2.584899      0.066225   \n",
       "3596      OLA    D300        0.019184       2.584899      0.066225   \n",
       "3597   Percep    D300        0.019184       2.584899      0.066225   \n",
       "3598  SVM_RBF    D300        0.019184       2.584899      0.066225   \n",
       "3599  SVM_lin    D300        0.019184       2.584899      0.066225   \n",
       "\n",
       "      best_node.mean  best_node.mean.relative        c1        c2  \\\n",
       "0           0.494839                      5.0  0.999928  0.000199   \n",
       "1           0.494839                      5.0  0.999928  0.000199   \n",
       "2           0.494839                      5.0  0.999928  0.000199   \n",
       "3           0.494839                      5.0  0.999928  0.000199   \n",
       "4           0.494839                      5.0  0.999928  0.000199   \n",
       "...              ...                      ...       ...       ...   \n",
       "3595        0.569462                      6.5  0.986003  0.037949   \n",
       "3596        0.569462                      6.5  0.986003  0.037949   \n",
       "3597        0.569462                      6.5  0.986003  0.037949   \n",
       "3598        0.569462                      6.5  0.986003  0.037949   \n",
       "3599        0.569462                      6.5  0.986003  0.037949   \n",
       "\n",
       "      can_cor.mean  ...  linearity.class.L3_partial.1        NS        SS  \\\n",
       "0         0.202900  ...                      0.448505  0.440079  0.466025   \n",
       "1         0.202900  ...                      0.448505  0.434862  0.462094   \n",
       "2         0.202900  ...                      0.448505  0.362818  0.474876   \n",
       "3         0.202900  ...                      0.448505  0.435348  0.447054   \n",
       "4         0.202900  ...                      0.448505  0.443713  0.468347   \n",
       "...            ...  ...                           ...       ...       ...   \n",
       "3595      0.250186  ...                      0.572848  0.601871  0.431757   \n",
       "3596      0.250186  ...                      0.572848  0.414099  0.445926   \n",
       "3597      0.250186  ...                      0.572848  0.265806  0.434663   \n",
       "3598      0.250186  ...                      0.572848  0.186589  0.190331   \n",
       "3599      0.250186  ...                      0.572848  0.026667  0.347853   \n",
       "\n",
       "           MMS       MAS        RS        QT  Max_F1_perf            Best_STs  \\\n",
       "0     0.394689  0.303649  0.449671  0.451235     0.466025              ['SS']   \n",
       "1     0.418003  0.445430  0.469747  0.487364     0.487364              ['QT']   \n",
       "2     0.384721  0.000000  0.484660  0.441929     0.484660              ['RS']   \n",
       "3     0.492395  0.450039  0.432771  0.413654     0.492395             ['MMS']   \n",
       "4     0.487077  0.432025  0.478051  0.505159     0.505159              ['QT']   \n",
       "...        ...       ...       ...       ...          ...                 ...   \n",
       "3595  0.601871  0.601871  0.438325  0.415073     0.601871  ['NS' 'MMS' 'MAS']   \n",
       "3596  0.386136  0.446185  0.376316  0.497744     0.497744              ['QT']   \n",
       "3597  0.237405  0.267137  0.377495  0.421451     0.434663              ['SS']   \n",
       "3598  0.201437  0.179149  0.217621  0.202262     0.217621              ['RS']   \n",
       "3599  0.121659  0.000000  0.326279  0.332856     0.347853              ['SS']   \n",
       "\n",
       "      Best_ST  \n",
       "0          SS  \n",
       "1          QT  \n",
       "2          RS  \n",
       "3         MMS  \n",
       "4          QT  \n",
       "...       ...  \n",
       "3595       NS  \n",
       "3596       QT  \n",
       "3597       SS  \n",
       "3598       RS  \n",
       "3599       SS  \n",
       "\n",
       "[3600 rows x 144 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_meta_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b31b065-a03e-4fee-8b46-60583cf7a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_names = our_meta_dataset['Model'].unique()\n",
    "jains_performances = {}\n",
    "for model in models_names:\n",
    "    jains_performances[model] = []\n",
    "    #Here we fetch only the performances attained by the current model when using SS and MMS:\n",
    "    perfs_for_this_model = our_meta_dataset[our_meta_dataset['Model'] == model].iloc[:,-8:-6].reset_index(drop=True)\n",
    "    #Now, we have to check what was Jain's predicted ST for each dataset and check what would be\n",
    "    #the performance of the current model with that ST on the dataset.\n",
    "    for ds in range(0,300):\n",
    "        jains_performances[model].append(perfs_for_this_model[y_pred[ds]].iloc[ds])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8b79ba2c-18a2-46a3-ae04-8e6d85d39317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bagging</th>\n",
       "      <th>GLVQ</th>\n",
       "      <th>GP</th>\n",
       "      <th>KNORAE</th>\n",
       "      <th>KNORAU</th>\n",
       "      <th>LCA</th>\n",
       "      <th>MCB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>OLA</th>\n",
       "      <th>Percep</th>\n",
       "      <th>SVM_RBF</th>\n",
       "      <th>SVM_lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394689</td>\n",
       "      <td>0.418003</td>\n",
       "      <td>0.384721</td>\n",
       "      <td>0.492395</td>\n",
       "      <td>0.487077</td>\n",
       "      <td>0.220839</td>\n",
       "      <td>0.492665</td>\n",
       "      <td>0.662205</td>\n",
       "      <td>0.535772</td>\n",
       "      <td>0.383329</td>\n",
       "      <td>0.453572</td>\n",
       "      <td>0.457443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.627831</td>\n",
       "      <td>0.619160</td>\n",
       "      <td>0.625233</td>\n",
       "      <td>0.586660</td>\n",
       "      <td>0.642697</td>\n",
       "      <td>0.455531</td>\n",
       "      <td>0.596047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591616</td>\n",
       "      <td>0.557115</td>\n",
       "      <td>0.587516</td>\n",
       "      <td>0.609299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366334</td>\n",
       "      <td>0.512624</td>\n",
       "      <td>0.485306</td>\n",
       "      <td>0.444194</td>\n",
       "      <td>0.450647</td>\n",
       "      <td>0.399639</td>\n",
       "      <td>0.470822</td>\n",
       "      <td>0.673568</td>\n",
       "      <td>0.451370</td>\n",
       "      <td>0.434061</td>\n",
       "      <td>0.451279</td>\n",
       "      <td>0.412555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464659</td>\n",
       "      <td>0.513954</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.424394</td>\n",
       "      <td>0.458579</td>\n",
       "      <td>0.420745</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.665201</td>\n",
       "      <td>0.442450</td>\n",
       "      <td>0.558772</td>\n",
       "      <td>0.448221</td>\n",
       "      <td>0.492700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.459579</td>\n",
       "      <td>0.624894</td>\n",
       "      <td>0.611336</td>\n",
       "      <td>0.460374</td>\n",
       "      <td>0.523039</td>\n",
       "      <td>0.408728</td>\n",
       "      <td>0.505028</td>\n",
       "      <td>0.692785</td>\n",
       "      <td>0.508054</td>\n",
       "      <td>0.305671</td>\n",
       "      <td>0.535946</td>\n",
       "      <td>0.514049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.544634</td>\n",
       "      <td>0.542386</td>\n",
       "      <td>0.375519</td>\n",
       "      <td>0.428957</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>0.538888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563854</td>\n",
       "      <td>0.527724</td>\n",
       "      <td>0.534791</td>\n",
       "      <td>0.533769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.686574</td>\n",
       "      <td>0.654669</td>\n",
       "      <td>0.676788</td>\n",
       "      <td>0.598052</td>\n",
       "      <td>0.681330</td>\n",
       "      <td>0.556507</td>\n",
       "      <td>0.635977</td>\n",
       "      <td>0.113043</td>\n",
       "      <td>0.616204</td>\n",
       "      <td>0.595677</td>\n",
       "      <td>0.684449</td>\n",
       "      <td>0.655115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.612490</td>\n",
       "      <td>0.666195</td>\n",
       "      <td>0.635883</td>\n",
       "      <td>0.456978</td>\n",
       "      <td>0.613727</td>\n",
       "      <td>0.591554</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.659512</td>\n",
       "      <td>0.551723</td>\n",
       "      <td>0.459202</td>\n",
       "      <td>0.605506</td>\n",
       "      <td>0.604518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.448158</td>\n",
       "      <td>0.149134</td>\n",
       "      <td>0.110849</td>\n",
       "      <td>0.424710</td>\n",
       "      <td>0.385779</td>\n",
       "      <td>0.504779</td>\n",
       "      <td>0.394609</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.392255</td>\n",
       "      <td>0.272819</td>\n",
       "      <td>0.622763</td>\n",
       "      <td>0.374748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.288707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.312977</td>\n",
       "      <td>0.210361</td>\n",
       "      <td>0.346649</td>\n",
       "      <td>0.601871</td>\n",
       "      <td>0.386136</td>\n",
       "      <td>0.237405</td>\n",
       "      <td>0.201437</td>\n",
       "      <td>0.121659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bagging      GLVQ        GP    KNORAE    KNORAU       LCA       MCB  \\\n",
       "0    0.394689  0.418003  0.384721  0.492395  0.487077  0.220839  0.492665   \n",
       "1    0.627831  0.619160  0.625233  0.586660  0.642697  0.455531  0.596047   \n",
       "2    0.366334  0.512624  0.485306  0.444194  0.450647  0.399639  0.470822   \n",
       "3    0.464659  0.513954  0.275781  0.424394  0.458579  0.420745  0.443409   \n",
       "4    0.459579  0.624894  0.611336  0.460374  0.523039  0.408728  0.505028   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  0.544634  0.542386  0.375519  0.428957  0.538095  0.504026  0.538888   \n",
       "296  0.686574  0.654669  0.676788  0.598052  0.681330  0.556507  0.635977   \n",
       "297  0.612490  0.666195  0.635883  0.456978  0.613727  0.591554  0.527027   \n",
       "298  0.448158  0.149134  0.110849  0.424710  0.385779  0.504779  0.394609   \n",
       "299  0.288707  0.000000  0.000000  0.427219  0.312977  0.210361  0.346649   \n",
       "\n",
       "          MLP       OLA    Percep   SVM_RBF   SVM_lin  \n",
       "0    0.662205  0.535772  0.383329  0.453572  0.457443  \n",
       "1    0.000000  0.591616  0.557115  0.587516  0.609299  \n",
       "2    0.673568  0.451370  0.434061  0.451279  0.412555  \n",
       "3    0.665201  0.442450  0.558772  0.448221  0.492700  \n",
       "4    0.692785  0.508054  0.305671  0.535946  0.514049  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "295  0.000000  0.563854  0.527724  0.534791  0.533769  \n",
       "296  0.113043  0.616204  0.595677  0.684449  0.655115  \n",
       "297  0.659512  0.551723  0.459202  0.605506  0.604518  \n",
       "298  0.666667  0.392255  0.272819  0.622763  0.374748  \n",
       "299  0.601871  0.386136  0.237405  0.201437  0.121659  \n",
       "\n",
       "[300 rows x 12 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(jains_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a0657447-249a-43bb-9204-2cf882dfc730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bagging</th>\n",
       "      <th>GLVQ</th>\n",
       "      <th>GP</th>\n",
       "      <th>KNORAE</th>\n",
       "      <th>KNORAU</th>\n",
       "      <th>LCA</th>\n",
       "      <th>MCB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>OLA</th>\n",
       "      <th>Percep</th>\n",
       "      <th>SVM_RBF</th>\n",
       "      <th>SVM_lin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.712870</td>\n",
       "      <td>0.624984</td>\n",
       "      <td>0.705526</td>\n",
       "      <td>0.722417</td>\n",
       "      <td>0.718334</td>\n",
       "      <td>0.676628</td>\n",
       "      <td>0.718868</td>\n",
       "      <td>0.687647</td>\n",
       "      <td>0.718981</td>\n",
       "      <td>0.678886</td>\n",
       "      <td>0.726086</td>\n",
       "      <td>0.702260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.276603</td>\n",
       "      <td>0.361435</td>\n",
       "      <td>0.318522</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>0.275972</td>\n",
       "      <td>0.276476</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.323022</td>\n",
       "      <td>0.241523</td>\n",
       "      <td>0.257378</td>\n",
       "      <td>0.287759</td>\n",
       "      <td>0.301822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.601652</td>\n",
       "      <td>0.408757</td>\n",
       "      <td>0.655037</td>\n",
       "      <td>0.585104</td>\n",
       "      <td>0.613499</td>\n",
       "      <td>0.522499</td>\n",
       "      <td>0.590553</td>\n",
       "      <td>0.622907</td>\n",
       "      <td>0.593792</td>\n",
       "      <td>0.525688</td>\n",
       "      <td>0.665153</td>\n",
       "      <td>0.588404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.792042</td>\n",
       "      <td>0.783934</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.807816</td>\n",
       "      <td>0.802952</td>\n",
       "      <td>0.751670</td>\n",
       "      <td>0.787938</td>\n",
       "      <td>0.804493</td>\n",
       "      <td>0.786939</td>\n",
       "      <td>0.742064</td>\n",
       "      <td>0.810698</td>\n",
       "      <td>0.798800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.922935</td>\n",
       "      <td>0.915278</td>\n",
       "      <td>0.929133</td>\n",
       "      <td>0.929048</td>\n",
       "      <td>0.924350</td>\n",
       "      <td>0.904144</td>\n",
       "      <td>0.914107</td>\n",
       "      <td>0.924678</td>\n",
       "      <td>0.914329</td>\n",
       "      <td>0.886834</td>\n",
       "      <td>0.929554</td>\n",
       "      <td>0.926884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.989058</td>\n",
       "      <td>0.990639</td>\n",
       "      <td>0.989733</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.991878</td>\n",
       "      <td>0.989058</td>\n",
       "      <td>0.991878</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.989058</td>\n",
       "      <td>0.991878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Bagging        GLVQ          GP      KNORAE      KNORAU         LCA  \\\n",
       "count  300.000000  300.000000  300.000000  300.000000  300.000000  300.000000   \n",
       "mean     0.712870    0.624984    0.705526    0.722417    0.718334    0.676628   \n",
       "std      0.276603    0.361435    0.318522    0.249137    0.275972    0.276476   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.601652    0.408757    0.655037    0.585104    0.613499    0.522499   \n",
       "50%      0.792042    0.783934    0.825006    0.807816    0.802952    0.751670   \n",
       "75%      0.922935    0.915278    0.929133    0.929048    0.924350    0.904144   \n",
       "max      0.991837    0.989058    0.990639    0.989733    0.991837    0.993939   \n",
       "\n",
       "              MCB         MLP         OLA      Percep     SVM_RBF     SVM_lin  \n",
       "count  300.000000  300.000000  300.000000  300.000000  300.000000  300.000000  \n",
       "mean     0.718868    0.687647    0.718981    0.678886    0.726086    0.702260  \n",
       "std      0.242325    0.323022    0.241523    0.257378    0.287759    0.301822  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.590553    0.622907    0.593792    0.525688    0.665153    0.588404  \n",
       "50%      0.787938    0.804493    0.786939    0.742064    0.810698    0.798800  \n",
       "75%      0.914107    0.924678    0.914329    0.886834    0.929554    0.926884  \n",
       "max      0.991878    0.989058    0.991878    0.991256    0.989058    0.991878  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(jains_performances).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "22750851-eb87-4233-8ff8-b10bfee68cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(jains_performances).to_csv('jain_et_al_classification_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6ee53-ef46-4acb-8b74-be968e3b33b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
